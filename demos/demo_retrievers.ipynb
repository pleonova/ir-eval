{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval: BM25 vs Jina Embeddings v4\n",
    "\n",
    "This notebook compares two retrieval approaches:\n",
    "- **BM25**: Traditional lexical (keyword-based) retrieval\n",
    "- **Jina Embeddings v4**: Modern semantic (meaning-based) retrieval\n",
    "\n",
    "We'll explore their strengths and weaknesses with carefully designed examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%%capture\n",
    "%pip install pandas==2.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Add parent directory to path so we can import from retrievers\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from retrievers.embeddings import JinaEmbedder, DummyEmbedder, EmbeddingRetriever\n",
    "from retrievers.bm25 import BM25\n",
    "from metrics import precision_at_k, mrr, ndcg_at_k\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='.*urllib3 v2.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Corpus\n",
    "\n",
    "We've designed this corpus to highlight different retrieval scenarios:\n",
    "1. **Exact keyword matches** - BM25 should excel\n",
    "2. **Semantic/paraphrased queries** - Embeddings should excel\n",
    "3. **Technical terms** - BM25's strength with rare terms\n",
    "4. **Conceptual understanding** - Embeddings' strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Corpus loaded from ../data/corpus.jsonl: 8 documents\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climate1</td>\n",
       "      <td>Climate change is causing rising sea levels an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climate2</td>\n",
       "      <td>Renewable energy sources like solar and wind p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml1</td>\n",
       "      <td>Machine learning algorithms can identify patte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml2</td>\n",
       "      <td>Deep neural networks use multiple layers to le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml3</td>\n",
       "      <td>Artificial intelligence systems can now unders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>space1</td>\n",
       "      <td>The James Webb Space Telescope is revealing un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>quantum1</td>\n",
       "      <td>Quantum computing leverages quantum entangleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bio1</td>\n",
       "      <td>CRISPR gene editing technology enables precise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id                                               text\n",
       "0  climate1  Climate change is causing rising sea levels an...\n",
       "1  climate2  Renewable energy sources like solar and wind p...\n",
       "2       ml1  Machine learning algorithms can identify patte...\n",
       "3       ml2  Deep neural networks use multiple layers to le...\n",
       "4       ml3  Artificial intelligence systems can now unders...\n",
       "5    space1  The James Webb Space Telescope is revealing un...\n",
       "6  quantum1  Quantum computing leverages quantum entangleme...\n",
       "7      bio1  CRISPR gene editing technology enables precise..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load corpus from data/corpus.jsonl\n",
    "corpus = []\n",
    "corpus_path = Path(\"../data/corpus.jsonl\")\n",
    "with open(corpus_path, 'r') as f:\n",
    "    for line in f:\n",
    "        entry = json.loads(line.strip())\n",
    "        corpus.append(entry)\n",
    "\n",
    "# Display corpus\n",
    "df_corpus = pd.DataFrame(corpus)\n",
    "print(f\"üìö Corpus loaded from {corpus_path}: {len(corpus)} documents\\n\")\n",
    "df_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Queries\n",
    "\n",
    "Each query is designed to test specific retrieval characteristics:\n",
    "\n",
    "### BM25 Strengths:\n",
    "- **Exact keywords** (queries 1, 4, 5)\n",
    "- **Rare technical terms**\n",
    "\n",
    "### Embedding Strengths:\n",
    "- **Semantic similarity** (queries 2, 7)\n",
    "- **Paraphrasing** (query 6)\n",
    "- **Conceptual understanding** (query 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Queries loaded from ../data/queries.jsonl: 7 test cases\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>type</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q1</td>\n",
       "      <td>quantum entanglement superposition</td>\n",
       "      <td>Exact keywords (BM25 strength)</td>\n",
       "      <td>quantum1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q2</td>\n",
       "      <td>global warming and rising temperatures</td>\n",
       "      <td>Semantic similarity (Embedding strength)</td>\n",
       "      <td>climate2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q3</td>\n",
       "      <td>How do computers learn from data?</td>\n",
       "      <td>Conceptual question (Embedding strength)</td>\n",
       "      <td>ml1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q4</td>\n",
       "      <td>CRISPR DNA editing</td>\n",
       "      <td>Exact technical terms (BM25 strength)</td>\n",
       "      <td>bio1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q5</td>\n",
       "      <td>James Webb infrared telescope</td>\n",
       "      <td>Multi-keyword match (BM25 strength)</td>\n",
       "      <td>space1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q6</td>\n",
       "      <td>AI that understands human language</td>\n",
       "      <td>Paraphrasing (Embedding strength)</td>\n",
       "      <td>ml3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>q7</td>\n",
       "      <td>environmental impact of CO2</td>\n",
       "      <td>Conceptual understanding (Embedding strength)</td>\n",
       "      <td>climate2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                   query  \\\n",
       "0  q1      quantum entanglement superposition   \n",
       "1  q2  global warming and rising temperatures   \n",
       "2  q3       How do computers learn from data?   \n",
       "3  q4                      CRISPR DNA editing   \n",
       "4  q5           James Webb infrared telescope   \n",
       "5  q6      AI that understands human language   \n",
       "6  q7             environmental impact of CO2   \n",
       "\n",
       "                                            type  expected  \n",
       "0                 Exact keywords (BM25 strength)  quantum1  \n",
       "1       Semantic similarity (Embedding strength)  climate2  \n",
       "2       Conceptual question (Embedding strength)       ml1  \n",
       "3          Exact technical terms (BM25 strength)      bio1  \n",
       "4            Multi-keyword match (BM25 strength)    space1  \n",
       "5              Paraphrasing (Embedding strength)       ml3  \n",
       "6  Conceptual understanding (Embedding strength)  climate2  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load queries from data/queries.jsonl\n",
    "queries_basic = []\n",
    "queries_path = Path(\"../data/queries.jsonl\")\n",
    "with open(queries_path, 'r') as f:\n",
    "    for line in f:\n",
    "        entry = json.loads(line.strip())\n",
    "        queries_basic.append(entry)\n",
    "\n",
    "# Add metadata for each query (expected doc, type, description)\n",
    "query_metadata = {\n",
    "    \"q1\": {\n",
    "        \"expected\": \"quantum1\",\n",
    "        \"type\": \"Exact keywords (BM25 strength)\",\n",
    "        \"description\": \"Contains rare, technical terms that appear in only one document\"\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"expected\": \"climate2\",\n",
    "        \"type\": \"Semantic similarity (Embedding strength)\",\n",
    "        \"description\": \"'global warming' is semantically similar to 'greenhouse gas emissions'\"\n",
    "    },\n",
    "    \"q3\": {\n",
    "        \"expected\": \"ml1\",\n",
    "        \"type\": \"Conceptual question (Embedding strength)\",\n",
    "        \"description\": \"Question form, no exact keywords but conceptually about machine learning\"\n",
    "    },\n",
    "    \"q4\": {\n",
    "        \"expected\": \"bio1\",\n",
    "        \"type\": \"Exact technical terms (BM25 strength)\",\n",
    "        \"description\": \"Specific acronym and technical terms\"\n",
    "    },\n",
    "    \"q5\": {\n",
    "        \"expected\": \"space1\",\n",
    "        \"type\": \"Multi-keyword match (BM25 strength)\",\n",
    "        \"description\": \"All three keywords appear in target document\"\n",
    "    },\n",
    "    \"q6\": {\n",
    "        \"expected\": \"ml3\",\n",
    "        \"type\": \"Paraphrasing (Embedding strength)\",\n",
    "        \"description\": \"Different words, same meaning as 'understand natural language'\"\n",
    "    },\n",
    "    \"q7\": {\n",
    "        \"expected\": \"climate2\",\n",
    "        \"type\": \"Conceptual understanding (Embedding strength)\",\n",
    "        \"description\": \"CO2 ‚Üí greenhouse gas, conceptual link without exact words\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Merge query text with metadata\n",
    "queries = []\n",
    "for q_basic in queries_basic:\n",
    "    qid = q_basic['qid']\n",
    "    metadata = query_metadata.get(qid, {})\n",
    "    queries.append({\n",
    "        \"id\": qid,\n",
    "        \"query\": q_basic['query'],\n",
    "        \"expected\": metadata.get(\"expected\", \"\"),\n",
    "        \"type\": metadata.get(\"type\", \"Unknown\"),\n",
    "        \"description\": metadata.get(\"description\", \"\")\n",
    "    })\n",
    "\n",
    "df_queries = pd.DataFrame(queries)\n",
    "print(f\"üîç Queries loaded from {queries_path}: {len(queries)} test cases\\n\")\n",
    "df_queries[[\"id\", \"query\", \"type\", \"expected\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. BM25 Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Initializing BM25 retriever...\n",
      "‚úì BM25 ready!\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Initializing BM25 retriever...\")\n",
    "bm25 = BM25()\n",
    "bm25.fit(corpus)\n",
    "print(\"‚úì BM25 ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Jina Embeddings Retriever\n",
    "\n",
    "**Note:** First run will download ~7.5GB model. Subsequent runs load from cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Loading Jina embeddings v4 model...\n",
      "   (This may take a few minutes on first run)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 8160.12it/s]\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 11.34it/s]\n",
      "Fetching 2 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 36314.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model loaded!\n",
      "‚úì Embedding dimension: 2048\n",
      "‚úì Normalized: True\n",
      "‚úì Jina retriever ready!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jina_retriever = None\n",
    "jina_embedder = None\n",
    "\n",
    "try:\n",
    "    print(\"üöÄ Loading Jina embeddings v4 model...\")\n",
    "    print(\"   (This may take a few minutes on first run)\\n\")\n",
    "    \n",
    "    jina_embedder = JinaEmbedder(model_name=\"jinaai/jina-embeddings-v4\", task=\"retrieval\")\n",
    "    print(\"‚úì Model loaded!\")\n",
    "    \n",
    "    # Test encoding\n",
    "    test_emb = jina_embedder.encode([\"test\"], prompt_name=\"passage\")\n",
    "    print(f\"‚úì Embedding dimension: {test_emb.shape[1]}\")\n",
    "    print(f\"‚úì Normalized: {np.allclose(np.linalg.norm(test_emb[0]), 1.0, rtol=1e-3)}\")\n",
    "    \n",
    "    jina_retriever = EmbeddingRetriever(embedder=jina_embedder)\n",
    "    jina_retriever.fit(corpus)\n",
    "    print(\"‚úì Jina retriever ready!\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading Jina model: {e}\")\n",
    "    print(\"   Install dependencies: pip install -r requirements.txt\")\n",
    "    print(\"   Continuing with BM25 only...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dummy Embeddings (Baseline)\n",
    "\n",
    "Random normalized embeddings for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ Initializing Dummy embedder (baseline)...\n",
      "‚úì Dummy retriever ready!\n"
     ]
    }
   ],
   "source": [
    "print(\"üé≤ Initializing Dummy embedder (baseline)...\")\n",
    "dummy_embedder = DummyEmbedder()\n",
    "dummy_retriever = EmbeddingRetriever(embedder=dummy_embedder)\n",
    "dummy_retriever.fit(corpus)\n",
    "print(\"‚úì Dummy retriever ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Retrieval Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_retrieval(retriever, query, k=3, name=\"Retriever\"):\n",
    "    \"\"\"Run retrieval and return results.\"\"\"\n",
    "    if retriever is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        results = retriever.rank(query, k=k)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {name}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def format_results(results, expected_doc=None):\n",
    "    \"\"\"Format results as dataframe with highlighting.\"\"\"\n",
    "    if results is None:\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(results, columns=[\"doc_id\", \"score\"])\n",
    "    df[\"rank\"] = range(1, len(df) + 1)\n",
    "    df[\"correct\"] = df[\"doc_id\"] == expected_doc if expected_doc else False\n",
    "    df = df[[\"rank\", \"doc_id\", \"score\", \"correct\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Results\n",
    "\n",
    "For each query, we'll show:\n",
    "- Top 3 results from each retriever\n",
    "- Whether the expected document was retrieved\n",
    "- Analysis of why each method succeeded or failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Query q1: quantum entanglement superposition\n",
      "Type: Exact keywords (BM25 strength)\n",
      "Expected: quantum1 - Contains rare, technical terms that appear in only one document\n",
      "================================================================================\n",
      "\n",
      "üìä BM25 Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>quantum1</td>\n",
       "      <td>5.626808</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>climate1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>climate2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1  quantum1  5.626808     True\n",
       "1     2  climate1  0.000000    False\n",
       "2     3  climate2  0.000000    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Jina Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>quantum1</td>\n",
       "      <td>0.654099</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>space1</td>\n",
       "      <td>0.435976</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ml3</td>\n",
       "      <td>0.430316</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1  quantum1  0.654099     True\n",
       "1     2    space1  0.435976    False\n",
       "2     3       ml3  0.430316    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≤ Dummy Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bio1</td>\n",
       "      <td>0.041708</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ml3</td>\n",
       "      <td>0.014613</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>quantum1</td>\n",
       "      <td>-0.007347</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1      bio1  0.041708    False\n",
       "1     2       ml3  0.014613    False\n",
       "2     3  quantum1 -0.007347     True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query q2: global warming and rising temperatures\n",
      "Type: Semantic similarity (Embedding strength)\n",
      "Expected: climate2 - 'global warming' is semantically similar to 'greenhouse gas emissions'\n",
      "================================================================================\n",
      "\n",
      "üìä BM25 Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>climate2</td>\n",
       "      <td>2.046342</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>climate1</td>\n",
       "      <td>1.914822</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ml3</td>\n",
       "      <td>0.190853</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1  climate2  2.046342     True\n",
       "1     2  climate1  1.914822    False\n",
       "2     3       ml3  0.190853    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Jina Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>climate1</td>\n",
       "      <td>0.754224</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>climate2</td>\n",
       "      <td>0.643384</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>space1</td>\n",
       "      <td>0.506174</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1  climate1  0.754224    False\n",
       "1     2  climate2  0.643384     True\n",
       "2     3    space1  0.506174    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≤ Dummy Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>climate1</td>\n",
       "      <td>0.060412</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>quantum1</td>\n",
       "      <td>0.025392</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ml2</td>\n",
       "      <td>-0.002697</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1  climate1  0.060412    False\n",
       "1     2  quantum1  0.025392    False\n",
       "2     3       ml2 -0.002697    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query q3: How do computers learn from data?\n",
      "Type: Conceptual question (Embedding strength)\n",
      "Expected: ml1 - Question form, no exact keywords but conceptually about machine learning\n",
      "================================================================================\n",
      "\n",
      "üìä BM25 Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ml2</td>\n",
       "      <td>1.829934</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>climate1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>climate2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1       ml2  1.829934    False\n",
       "1     2  climate1  0.000000    False\n",
       "2     3  climate2  0.000000    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Jina Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ml1</td>\n",
       "      <td>0.620494</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ml2</td>\n",
       "      <td>0.591145</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>quantum1</td>\n",
       "      <td>0.524754</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1       ml1  0.620494     True\n",
       "1     2       ml2  0.591145    False\n",
       "2     3  quantum1  0.524754    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≤ Dummy Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ml2</td>\n",
       "      <td>0.106231</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ml3</td>\n",
       "      <td>0.044280</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>space1</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  doc_id     score  correct\n",
       "0     1     ml2  0.106231    False\n",
       "1     2     ml3  0.044280    False\n",
       "2     3  space1  0.001975    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query q4: CRISPR DNA editing\n",
      "Type: Exact technical terms (BM25 strength)\n",
      "Expected: bio1 - Specific acronym and technical terms\n",
      "================================================================================\n",
      "\n",
      "üìä BM25 Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bio1</td>\n",
       "      <td>5.234873</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>climate1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>climate2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1      bio1  5.234873     True\n",
       "1     2  climate1  0.000000    False\n",
       "2     3  climate2  0.000000    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Jina Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bio1</td>\n",
       "      <td>0.766719</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ml3</td>\n",
       "      <td>0.422570</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>quantum1</td>\n",
       "      <td>0.403295</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1      bio1  0.766719     True\n",
       "1     2       ml3  0.422570    False\n",
       "2     3  quantum1  0.403295    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≤ Dummy Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ml3</td>\n",
       "      <td>0.128329</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>climate2</td>\n",
       "      <td>0.069529</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>climate1</td>\n",
       "      <td>0.059128</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1       ml3  0.128329    False\n",
       "1     2  climate2  0.069529    False\n",
       "2     3  climate1  0.059128    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query q5: James Webb infrared telescope\n",
      "Type: Multi-keyword match (BM25 strength)\n",
      "Expected: space1 - All three keywords appear in target document\n",
      "================================================================================\n",
      "\n",
      "üìä BM25 Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>space1</td>\n",
       "      <td>5.359307</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>climate1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>climate2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1    space1  5.359307     True\n",
       "1     2  climate1  0.000000    False\n",
       "2     3  climate2  0.000000    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Jina Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>space1</td>\n",
       "      <td>0.790224</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ml3</td>\n",
       "      <td>0.388030</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>climate1</td>\n",
       "      <td>0.383982</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1    space1  0.790224     True\n",
       "1     2       ml3  0.388030    False\n",
       "2     3  climate1  0.383982    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≤ Dummy Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ml2</td>\n",
       "      <td>0.071142</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ml3</td>\n",
       "      <td>0.036583</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>bio1</td>\n",
       "      <td>0.015456</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank doc_id     score  correct\n",
       "0     1    ml2  0.071142    False\n",
       "1     2    ml3  0.036583    False\n",
       "2     3   bio1  0.015456    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query q6: AI that understands human language\n",
      "Type: Paraphrasing (Embedding strength)\n",
      "Expected: ml3 - Different words, same meaning as 'understand natural language'\n",
      "================================================================================\n",
      "\n",
      "üìä BM25 Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>climate1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>climate2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ml1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id  score  correct\n",
       "0     1  climate1    0.0    False\n",
       "1     2  climate2    0.0    False\n",
       "2     3       ml1    0.0    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Jina Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ml3</td>\n",
       "      <td>0.752927</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ml1</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ml2</td>\n",
       "      <td>0.548452</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank doc_id     score  correct\n",
       "0     1    ml3  0.752927     True\n",
       "1     2    ml1  0.592000    False\n",
       "2     3    ml2  0.548452    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≤ Dummy Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>climate2</td>\n",
       "      <td>0.045536</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ml2</td>\n",
       "      <td>0.029190</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ml3</td>\n",
       "      <td>0.026435</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1  climate2  0.045536    False\n",
       "1     2       ml2  0.029190    False\n",
       "2     3       ml3  0.026435     True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query q7: environmental impact of CO2\n",
      "Type: Conceptual understanding (Embedding strength)\n",
      "Expected: climate2 - CO2 ‚Üí greenhouse gas, conceptual link without exact words\n",
      "================================================================================\n",
      "\n",
      "üìä BM25 Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ml2</td>\n",
       "      <td>1.308225</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>climate1</td>\n",
       "      <td>1.192117</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>climate2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1       ml2  1.308225    False\n",
       "1     2  climate1  1.192117    False\n",
       "2     3  climate2  0.000000     True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Jina Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>climate1</td>\n",
       "      <td>0.650154</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>climate2</td>\n",
       "      <td>0.610414</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>space1</td>\n",
       "      <td>0.433448</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1  climate1  0.650154    False\n",
       "1     2  climate2  0.610414     True\n",
       "2     3    space1  0.433448    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≤ Dummy Embeddings Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>quantum1</td>\n",
       "      <td>0.085921</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>space1</td>\n",
       "      <td>0.066898</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ml3</td>\n",
       "      <td>0.053408</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank    doc_id     score  correct\n",
       "0     1  quantum1  0.085921    False\n",
       "1     2    space1  0.066898    False\n",
       "2     3       ml3  0.053408    False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store all results\n",
    "all_results = []\n",
    "\n",
    "for q in queries:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Query {q['id']}: {q['query']}\")\n",
    "    print(f\"Type: {q['type']}\")\n",
    "    print(f\"Expected: {q['expected']} - {q['description']}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # BM25\n",
    "    print(\"\\nüìä BM25 Results:\")\n",
    "    bm25_results = run_retrieval(bm25, q['query'], k=3, name=\"BM25\")\n",
    "    bm25_df = format_results(bm25_results, q['expected'])\n",
    "    if bm25_df is not None:\n",
    "        display(bm25_df)\n",
    "        bm25_correct = bm25_df[bm25_df['correct']].shape[0] > 0\n",
    "        bm25_rank = bm25_df[bm25_df['correct']]['rank'].values[0] if bm25_correct else None\n",
    "    else:\n",
    "        bm25_correct = False\n",
    "        bm25_rank = None\n",
    "    \n",
    "    # Jina Embeddings\n",
    "    print(\"\\nüöÄ Jina Embeddings Results:\")\n",
    "    jina_results = run_retrieval(jina_retriever, q['query'], k=3, name=\"Jina\")\n",
    "    jina_df = format_results(jina_results, q['expected'])\n",
    "    if jina_df is not None:\n",
    "        display(jina_df)\n",
    "        jina_correct = jina_df[jina_df['correct']].shape[0] > 0\n",
    "        jina_rank = jina_df[jina_df['correct']]['rank'].values[0] if jina_correct else None\n",
    "    else:\n",
    "        print(\"   (Not available)\")\n",
    "        jina_correct = False\n",
    "        jina_rank = None\n",
    "    \n",
    "    # Dummy (baseline)\n",
    "    print(\"\\nüé≤ Dummy Embeddings Results:\")\n",
    "    dummy_results = run_retrieval(dummy_retriever, q['query'], k=3, name=\"Dummy\")\n",
    "    dummy_df = format_results(dummy_results, q['expected'])\n",
    "    if dummy_df is not None:\n",
    "        display(dummy_df)\n",
    "        dummy_correct = dummy_df[dummy_df['correct']].shape[0] > 0\n",
    "        dummy_rank = dummy_df[dummy_df['correct']]['rank'].values[0] if dummy_correct else None\n",
    "    else:\n",
    "        dummy_correct = False\n",
    "        dummy_rank = None\n",
    "    \n",
    "    # Store results\n",
    "    all_results.append({\n",
    "        'query_id': q['id'],\n",
    "        'query': q['query'],\n",
    "        'type': q['type'],\n",
    "        'expected': q['expected'],\n",
    "        'bm25_correct': bm25_correct,\n",
    "        'bm25_rank': bm25_rank,\n",
    "        'jina_correct': jina_correct,\n",
    "        'jina_rank': jina_rank,\n",
    "        'dummy_correct': dummy_correct,\n",
    "        'dummy_rank': dummy_rank,\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUMMARY: Retrieval Performance\n",
      "================================================================================\n",
      "\n",
      "üìä Accuracy (found expected document in top 3):\n",
      "  BM25:            5/7 = 71.4%\n",
      "  Jina Embeddings: 7/7 = 100.0%\n",
      "  Dummy (baseline): 2/7 = 28.6%\n",
      "\n",
      "üìà Performance by Query Type:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bm25_correct</th>\n",
       "      <th>jina_correct</th>\n",
       "      <th>dummy_correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Conceptual question (Embedding strength)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conceptual understanding (Embedding strength)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exact keywords (BM25 strength)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exact technical terms (BM25 strength)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-keyword match (BM25 strength)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paraphrasing (Embedding strength)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Semantic similarity (Embedding strength)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               bm25_correct  jina_correct  \\\n",
       "type                                                                        \n",
       "Conceptual question (Embedding strength)                0.0           1.0   \n",
       "Conceptual understanding (Embedding strength)           1.0           1.0   \n",
       "Exact keywords (BM25 strength)                          1.0           1.0   \n",
       "Exact technical terms (BM25 strength)                   1.0           1.0   \n",
       "Multi-keyword match (BM25 strength)                     1.0           1.0   \n",
       "Paraphrasing (Embedding strength)                       0.0           1.0   \n",
       "Semantic similarity (Embedding strength)                1.0           1.0   \n",
       "\n",
       "                                               dummy_correct  \n",
       "type                                                          \n",
       "Conceptual question (Embedding strength)                 0.0  \n",
       "Conceptual understanding (Embedding strength)            0.0  \n",
       "Exact keywords (BM25 strength)                           1.0  \n",
       "Exact technical terms (BM25 strength)                    0.0  \n",
       "Multi-keyword match (BM25 strength)                      0.0  \n",
       "Paraphrasing (Embedding strength)                        1.0  \n",
       "Semantic similarity (Embedding strength)                 0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° Full Results Table:\n",
      "(Rank shows position 1-3 if found, '>3' if not in top 3)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>type</th>\n",
       "      <th>expected</th>\n",
       "      <th>bm25_correct</th>\n",
       "      <th>bm25_rank</th>\n",
       "      <th>jina_correct</th>\n",
       "      <th>jina_rank</th>\n",
       "      <th>dummy_correct</th>\n",
       "      <th>dummy_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q1</td>\n",
       "      <td>quantum entanglement superposition</td>\n",
       "      <td>Exact keywords (BM25 strength)</td>\n",
       "      <td>quantum1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q2</td>\n",
       "      <td>global warming and rising temperatures</td>\n",
       "      <td>Semantic similarity (Embedding strength)</td>\n",
       "      <td>climate2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q3</td>\n",
       "      <td>How do computers learn from data?</td>\n",
       "      <td>Conceptual question (Embedding strength)</td>\n",
       "      <td>ml1</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q4</td>\n",
       "      <td>CRISPR DNA editing</td>\n",
       "      <td>Exact technical terms (BM25 strength)</td>\n",
       "      <td>bio1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q5</td>\n",
       "      <td>James Webb infrared telescope</td>\n",
       "      <td>Multi-keyword match (BM25 strength)</td>\n",
       "      <td>space1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q6</td>\n",
       "      <td>AI that understands human language</td>\n",
       "      <td>Paraphrasing (Embedding strength)</td>\n",
       "      <td>ml3</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>q7</td>\n",
       "      <td>environmental impact of CO2</td>\n",
       "      <td>Conceptual understanding (Embedding strength)</td>\n",
       "      <td>climate2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id                                   query  \\\n",
       "0       q1      quantum entanglement superposition   \n",
       "1       q2  global warming and rising temperatures   \n",
       "2       q3       How do computers learn from data?   \n",
       "3       q4                      CRISPR DNA editing   \n",
       "4       q5           James Webb infrared telescope   \n",
       "5       q6      AI that understands human language   \n",
       "6       q7             environmental impact of CO2   \n",
       "\n",
       "                                            type  expected  bm25_correct  \\\n",
       "0                 Exact keywords (BM25 strength)  quantum1          True   \n",
       "1       Semantic similarity (Embedding strength)  climate2          True   \n",
       "2       Conceptual question (Embedding strength)       ml1         False   \n",
       "3          Exact technical terms (BM25 strength)      bio1          True   \n",
       "4            Multi-keyword match (BM25 strength)    space1          True   \n",
       "5              Paraphrasing (Embedding strength)       ml3         False   \n",
       "6  Conceptual understanding (Embedding strength)  climate2          True   \n",
       "\n",
       "  bm25_rank  jina_correct jina_rank  dummy_correct dummy_rank  \n",
       "0         1          True         1           True          3  \n",
       "1         1          True         2          False         >3  \n",
       "2        >3          True         1          False         >3  \n",
       "3         1          True         1          False         >3  \n",
       "4         1          True         1          False         >3  \n",
       "5        >3          True         1           True          3  \n",
       "6         3          True         2          False         >3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY: Retrieval Performance\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Overall accuracy\n",
    "print(\"\\nüìä Accuracy (found expected document in top 3):\")\n",
    "print(f\"  BM25:            {df_results['bm25_correct'].sum()}/{len(queries)} = {df_results['bm25_correct'].mean():.1%}\")\n",
    "if jina_retriever:\n",
    "    print(f\"  Jina Embeddings: {df_results['jina_correct'].sum()}/{len(queries)} = {df_results['jina_correct'].mean():.1%}\")\n",
    "print(f\"  Dummy (baseline): {df_results['dummy_correct'].sum()}/{len(queries)} = {df_results['dummy_correct'].mean():.1%}\")\n",
    "\n",
    "# By query type\n",
    "print(\"\\nüìà Performance by Query Type:\")\n",
    "display(df_results.groupby('type').agg({\n",
    "    'bm25_correct': 'mean',\n",
    "    'jina_correct': 'mean',\n",
    "    'dummy_correct': 'mean'\n",
    "}).round(2))\n",
    "\n",
    "print(\"\\nüí° Full Results Table:\")\n",
    "print(\"(Rank shows position 1-3 if found, '>3' if not in top 3)\\n\")\n",
    "\n",
    "# Replace NaN with \">3\" for better readability\n",
    "df_results_display = df_results.copy()\n",
    "rank_columns = ['bm25_rank', 'jina_rank', 'dummy_rank']\n",
    "for col in rank_columns:\n",
    "    if col in df_results_display.columns:\n",
    "        df_results_display[col] = df_results_display[col].fillna('>3').astype(str).str.replace('.0', '', regex=False)\n",
    "\n",
    "display(df_results_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Metrics Analysis\n",
    "\n",
    "Let's calculate standard IR metrics: **Precision@k**, **MRR** (Mean Reciprocal Rank), and **NDCG@k** (Normalized Discounted Cumulative Gain).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Calculating IR Metrics (P@3, MRR, NDCG@3)...\n",
      "\n",
      "================================================================================\n",
      "IR METRICS COMPARISON\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@3</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG@3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BM25</th>\n",
       "      <td>0.238</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jina Embeddings</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy (baseline)</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    P@3    MRR  NDCG@3\n",
       "BM25              0.238  0.619   0.643\n",
       "Jina Embeddings   0.333  0.857   0.895\n",
       "Dummy (baseline)  0.095  0.095   0.143"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ Metric Definitions:\n",
      "  ‚Ä¢ P@3 (Precision@3): Fraction of relevant docs in top 3 results\n",
      "  ‚Ä¢ MRR (Mean Reciprocal Rank): Average of 1/rank of first relevant doc\n",
      "  ‚Ä¢ NDCG@3: Normalized DCG - measures ranking quality (0-1, higher=better)\n",
      "\n",
      "üí° All metrics averaged across all queries. Higher is better!\n"
     ]
    }
   ],
   "source": [
    "# Build qrels (query relevance judgments) from our queries\n",
    "# Each query has exactly one expected document with relevance score 1\n",
    "qrels = {}\n",
    "for q in queries:\n",
    "    qrels[q['id']] = {q['expected']: 1}\n",
    "\n",
    "# Build run dictionaries (query_id -> ranked list of doc_ids) for each retriever\n",
    "def build_run_dict(all_results):\n",
    "    \"\"\"Convert results to format expected by metrics: {qid: [ranked_doc_ids]}\"\"\"\n",
    "    run = {}\n",
    "    for result in all_results:\n",
    "        qid = result['query_id']\n",
    "        query_text = result['query']\n",
    "        \n",
    "        # Get top-3 results from each retriever\n",
    "        bm25_results = bm25.rank(query_text, k=3)\n",
    "        run[qid] = [doc_id for doc_id, score in bm25_results]\n",
    "    return run\n",
    "\n",
    "# Build runs for each retriever\n",
    "print(\"üìä Calculating IR Metrics (P@3, MRR, NDCG@3)...\\n\")\n",
    "\n",
    "# BM25 run\n",
    "bm25_run = {}\n",
    "for q in queries:\n",
    "    results = bm25.rank(q['query'], k=3)\n",
    "    bm25_run[q['id']] = [doc_id for doc_id, score in results]\n",
    "\n",
    "# Jina run\n",
    "jina_run = {}\n",
    "if jina_retriever:\n",
    "    for q in queries:\n",
    "        results = jina_retriever.rank(q['query'], k=3)\n",
    "        jina_run[q['id']] = [doc_id for doc_id, score in results]\n",
    "\n",
    "# Dummy run\n",
    "dummy_run = {}\n",
    "for q in queries:\n",
    "    results = dummy_retriever.rank(q['query'], k=3)\n",
    "    dummy_run[q['id']] = [doc_id for doc_id, score in results]\n",
    "\n",
    "# Calculate metrics for each retriever\n",
    "def calculate_metrics(run, qrels, k=3):\n",
    "    \"\"\"Calculate average metrics across all queries.\"\"\"\n",
    "    p_sum = mrr_sum = ndcg_sum = 0.0\n",
    "    n_queries = 0\n",
    "    \n",
    "    for qid, ranked_ids in run.items():\n",
    "        if qid not in qrels:\n",
    "            continue\n",
    "        n_queries += 1\n",
    "        p_sum += precision_at_k(ranked_ids, qrels[qid], k)\n",
    "        mrr_sum += mrr(ranked_ids, qrels[qid])\n",
    "        ndcg_sum += ndcg_at_k(ranked_ids, qrels[qid], k, method=\"exponential\")\n",
    "    \n",
    "    if n_queries == 0:\n",
    "        return {\"P@k\": 0.0, \"MRR\": 0.0, \"NDCG@k\": 0.0}\n",
    "    \n",
    "    return {\n",
    "        f\"P@{k}\": round(p_sum / n_queries, 3),\n",
    "        \"MRR\": round(mrr_sum / n_queries, 3),\n",
    "        f\"NDCG@{k}\": round(ndcg_sum / n_queries, 3)\n",
    "    }\n",
    "\n",
    "# Calculate metrics for each retriever\n",
    "k = 3\n",
    "bm25_metrics = calculate_metrics(bm25_run, qrels, k=k)\n",
    "jina_metrics = calculate_metrics(jina_run, qrels, k=k) if jina_retriever else {\"P@3\": 0.0, \"MRR\": 0.0, \"NDCG@3\": 0.0}\n",
    "dummy_metrics = calculate_metrics(dummy_run, qrels, k=k)\n",
    "\n",
    "# Create comparison table\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'BM25': bm25_metrics,\n",
    "    'Jina Embeddings': jina_metrics,\n",
    "    'Dummy (baseline)': dummy_metrics\n",
    "}).T\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"IR METRICS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "display(metrics_comparison)\n",
    "\n",
    "print(\"\\nüìñ Metric Definitions:\")\n",
    "print(f\"  ‚Ä¢ P@{k} (Precision@{k}): Fraction of relevant docs in top {k} results\")\n",
    "print(\"  ‚Ä¢ MRR (Mean Reciprocal Rank): Average of 1/rank of first relevant doc\")\n",
    "print(f\"  ‚Ä¢ NDCG@{k}: Normalized DCG - measures ranking quality (0-1, higher=better)\")\n",
    "print(\"\\nüí° All metrics averaged across all queries. Higher is better!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Query Metrics Breakdown\n",
    "\n",
    "Let's examine metrics for each individual query to understand where each retriever excels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Per-Query Metrics Breakdown:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query ID</th>\n",
       "      <th>Query Type</th>\n",
       "      <th>BM25 P@1</th>\n",
       "      <th>BM25 MRR</th>\n",
       "      <th>BM25 NDCG@3</th>\n",
       "      <th>Jina P@1</th>\n",
       "      <th>Jina MRR</th>\n",
       "      <th>Jina NDCG@3</th>\n",
       "      <th>Dummy P@1</th>\n",
       "      <th>Dummy MRR</th>\n",
       "      <th>Dummy NDCG@3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q1</td>\n",
       "      <td>Exact keywords (BM25 strength)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q2</td>\n",
       "      <td>Semantic similarity (Embedding strength)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q3</td>\n",
       "      <td>Conceptual question (Embedding strength)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q4</td>\n",
       "      <td>Exact technical terms (BM25 strength)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q5</td>\n",
       "      <td>Multi-keyword match (BM25 strength)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q6</td>\n",
       "      <td>Paraphrasing (Embedding strength)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>q7</td>\n",
       "      <td>Conceptual understanding (Embedding strength)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AVERAGE</td>\n",
       "      <td>All queries</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Query ID                                     Query Type  BM25 P@1  BM25 MRR  \\\n",
       "0       q1                 Exact keywords (BM25 strength)      1.00      1.00   \n",
       "1       q2       Semantic similarity (Embedding strength)      1.00      1.00   \n",
       "2       q3       Conceptual question (Embedding strength)      0.00      0.00   \n",
       "3       q4          Exact technical terms (BM25 strength)      1.00      1.00   \n",
       "4       q5            Multi-keyword match (BM25 strength)      1.00      1.00   \n",
       "5       q6              Paraphrasing (Embedding strength)      0.00      0.00   \n",
       "6       q7  Conceptual understanding (Embedding strength)      0.00      0.33   \n",
       "7  AVERAGE                                    All queries      0.57      0.62   \n",
       "\n",
       "   BM25 NDCG@3  Jina P@1  Jina MRR  Jina NDCG@3  Dummy P@1  Dummy MRR  \\\n",
       "0         1.00      1.00      1.00         1.00        0.0       0.33   \n",
       "1         1.00      0.00      0.50         0.63        0.0       0.00   \n",
       "2         0.00      1.00      1.00         1.00        0.0       0.00   \n",
       "3         1.00      1.00      1.00         1.00        0.0       0.00   \n",
       "4         1.00      1.00      1.00         1.00        0.0       0.00   \n",
       "5         0.00      1.00      1.00         1.00        0.0       0.33   \n",
       "6         0.50      0.00      0.50         0.63        0.0       0.00   \n",
       "7         0.64      0.71      0.86         0.89        0.0       0.09   \n",
       "\n",
       "   Dummy NDCG@3  \n",
       "0          0.50  \n",
       "1          0.00  \n",
       "2          0.00  \n",
       "3          0.00  \n",
       "4          0.00  \n",
       "5          0.50  \n",
       "6          0.00  \n",
       "7          0.14  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Best Performer by Query Type (based on NDCG@3):\n",
      "  ‚Ä¢ Exact keywords (BM25 strength)... ‚Üí BM25 (1.00)\n",
      "  ‚Ä¢ Semantic similarity (Embedding strength)... ‚Üí BM25 (1.00)\n",
      "  ‚Ä¢ Conceptual question (Embedding strength)... ‚Üí Jina (1.00)\n",
      "  ‚Ä¢ Exact technical terms (BM25 strength)... ‚Üí BM25 (1.00)\n",
      "  ‚Ä¢ Multi-keyword match (BM25 strength)... ‚Üí BM25 (1.00)\n",
      "  ‚Ä¢ Paraphrasing (Embedding strength)... ‚Üí Jina (1.00)\n",
      "  ‚Ä¢ Conceptual understanding (Embedding strength)... ‚Üí Jina (0.63)\n"
     ]
    }
   ],
   "source": [
    "# Calculate per-query metrics\n",
    "per_query_metrics = []\n",
    "\n",
    "for q in queries:\n",
    "    qid = q['id']\n",
    "    qtype = q['type']\n",
    "    \n",
    "    # BM25 metrics\n",
    "    bm25_ranked = bm25_run[qid]\n",
    "    bm25_p = precision_at_k(bm25_ranked, qrels[qid], k=1)\n",
    "    bm25_mrr = mrr(bm25_ranked, qrels[qid])\n",
    "    bm25_ndcg = ndcg_at_k(bm25_ranked, qrels[qid], k=3, method=\"exponential\")\n",
    "    \n",
    "    # Jina metrics\n",
    "    if jina_retriever:\n",
    "        jina_ranked = jina_run[qid]\n",
    "        jina_p = precision_at_k(jina_ranked, qrels[qid], k=1)\n",
    "        jina_mrr = mrr(jina_ranked, qrels[qid])\n",
    "        jina_ndcg = ndcg_at_k(jina_ranked, qrels[qid], k=3, method=\"exponential\")\n",
    "    else:\n",
    "        jina_p = jina_mrr = jina_ndcg = 0.0\n",
    "    \n",
    "    # Dummy metrics\n",
    "    dummy_ranked = dummy_run[qid]\n",
    "    dummy_p = precision_at_k(dummy_ranked, qrels[qid], k=1)\n",
    "    dummy_mrr = mrr(dummy_ranked, qrels[qid])\n",
    "    dummy_ndcg = ndcg_at_k(dummy_ranked, qrels[qid], k=3, method=\"exponential\")\n",
    "    \n",
    "    per_query_metrics.append({\n",
    "        'Query ID': qid,\n",
    "        'Query Type': qtype,\n",
    "        'BM25 P@1': round(bm25_p, 2),\n",
    "        'BM25 MRR': round(bm25_mrr, 2),\n",
    "        'BM25 NDCG@3': round(bm25_ndcg, 2),\n",
    "        'Jina P@1': round(jina_p, 2),\n",
    "        'Jina MRR': round(jina_mrr, 2),\n",
    "        'Jina NDCG@3': round(jina_ndcg, 2),\n",
    "        'Dummy P@1': round(dummy_p, 2),\n",
    "        'Dummy MRR': round(dummy_mrr, 2),\n",
    "        'Dummy NDCG@3': round(dummy_ndcg, 2),\n",
    "    })\n",
    "\n",
    "df_per_query = pd.DataFrame(per_query_metrics)\n",
    "\n",
    "# Calculate aggregate scores (mean across all queries)\n",
    "aggregate_row = {\n",
    "    'Query ID': 'AVERAGE',\n",
    "    'Query Type': 'All queries',\n",
    "    'BM25 P@1': round(df_per_query['BM25 P@1'].mean(), 2),\n",
    "    'BM25 MRR': round(df_per_query['BM25 MRR'].mean(), 2),\n",
    "    'BM25 NDCG@3': round(df_per_query['BM25 NDCG@3'].mean(), 2),\n",
    "    'Jina P@1': round(df_per_query['Jina P@1'].mean(), 2),\n",
    "    'Jina MRR': round(df_per_query['Jina MRR'].mean(), 2),\n",
    "    'Jina NDCG@3': round(df_per_query['Jina NDCG@3'].mean(), 2),\n",
    "    'Dummy P@1': round(df_per_query['Dummy P@1'].mean(), 2),\n",
    "    'Dummy MRR': round(df_per_query['Dummy MRR'].mean(), 2),\n",
    "    'Dummy NDCG@3': round(df_per_query['Dummy NDCG@3'].mean(), 2),\n",
    "}\n",
    "\n",
    "# Add aggregate row to the dataframe\n",
    "df_per_query_with_avg = pd.concat([df_per_query, pd.DataFrame([aggregate_row])], ignore_index=True)\n",
    "\n",
    "# Display with better formatting\n",
    "print(\"üìä Per-Query Metrics Breakdown:\\n\")\n",
    "display(df_per_query_with_avg)\n",
    "\n",
    "# Highlight best performing retriever for each query type\n",
    "print(\"\\nüèÜ Best Performer by Query Type (based on NDCG@3):\")\n",
    "for qtype in df_per_query['Query Type'].unique():\n",
    "    type_rows = df_per_query[df_per_query['Query Type'] == qtype]\n",
    "    avg_bm25 = type_rows['BM25 NDCG@3'].mean()\n",
    "    avg_jina = type_rows['Jina NDCG@3'].mean()\n",
    "    avg_dummy = type_rows['Dummy NDCG@3'].mean()\n",
    "    \n",
    "    best = max([('BM25', avg_bm25), ('Jina', avg_jina), ('Dummy', avg_dummy)], key=lambda x: x[1])\n",
    "    print(f\"  ‚Ä¢ {qtype[:50]}... ‚Üí {best[0]} ({best[1]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Relevance Scoring\n",
    "\n",
    "**Why use graded relevance instead of binary?**\n",
    "\n",
    "So far, we've used binary relevance (relevant=1, not relevant=0). But in real-world IR, documents can be:\n",
    "- **Highly relevant** (rel=3): Perfect match, directly answers the query\n",
    "- **Moderately relevant** (rel=2): Partially relevant, contains useful info\n",
    "- **Somewhat relevant** (rel=1): Tangentially related\n",
    "- **Not relevant** (rel=0): Irrelevant\n",
    "\n",
    "NDCG is particularly well-suited for graded relevance because it rewards systems that rank highly-relevant documents higher.\n",
    "\n",
    "Let's compare binary vs graded relevance using our qrels from `data/qrels.jsonl`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loaded graded relevance judgments from data/qrels.jsonl\n",
      "Queries with graded qrels: 7\n",
      "\n",
      "Example: Query 'q2' (global warming):\n",
      "  climate2: rel=3 (highly relevant)\n",
      "  climate1: rel=2 (moderately relevant)\n",
      "\n",
      "================================================================================\n",
      "BINARY vs GRADED RELEVANCE COMPARISON (NDCG@3)\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query ID</th>\n",
       "      <th>Query</th>\n",
       "      <th>BM25 NDCG (Binary)</th>\n",
       "      <th>BM25 NDCG (Graded)</th>\n",
       "      <th>BM25 Œî</th>\n",
       "      <th>Jina NDCG (Binary)</th>\n",
       "      <th>Jina NDCG (Graded)</th>\n",
       "      <th>Jina Œî</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q1</td>\n",
       "      <td>quantum entanglement superposition...</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.304</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q2</td>\n",
       "      <td>global warming and rising temperatures...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.834</td>\n",
       "      <td>-0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q3</td>\n",
       "      <td>How do computers learn from data?...</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.319</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q4</td>\n",
       "      <td>CRISPR DNA editing...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q5</td>\n",
       "      <td>James Webb infrared telescope...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q6</td>\n",
       "      <td>AI that understands human language...</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>q7</td>\n",
       "      <td>environmental impact of CO2...</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.606</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.834</td>\n",
       "      <td>-0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AVERAGE</td>\n",
       "      <td>All queries</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.701</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.945</td>\n",
       "      <td>-0.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Query ID                                      Query  BM25 NDCG (Binary)  \\\n",
       "0       q1      quantum entanglement superposition...               0.613   \n",
       "1       q2  global warming and rising temperatures...               1.000   \n",
       "2       q3       How do computers learn from data?...               0.469   \n",
       "3       q4                      CRISPR DNA editing...               1.000   \n",
       "4       q5           James Webb infrared telescope...               1.000   \n",
       "5       q6      AI that understands human language...               0.307   \n",
       "6       q7             environmental impact of CO2...               0.693   \n",
       "7  AVERAGE                                All queries               0.726   \n",
       "\n",
       "   BM25 NDCG (Graded)  BM25 Œî  Jina NDCG (Binary)  Jina NDCG (Graded)  Jina Œî  \n",
       "0               0.917   0.304               1.000               1.000   0.000  \n",
       "1               1.000   0.000               1.000               0.834  -0.166  \n",
       "2               0.319  -0.150               0.765               0.947   0.181  \n",
       "3               1.000   0.000               1.000               1.000   0.000  \n",
       "4               1.000   0.000               1.000               1.000   0.000  \n",
       "5               0.066  -0.241               1.000               1.000   0.000  \n",
       "6               0.606  -0.087               1.000               0.834  -0.166  \n",
       "7               0.701  -0.025               0.966               0.945  -0.021  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° Key Insights:\n",
      "  ‚Ä¢ Graded relevance reveals finer differences in ranking quality\n",
      "  ‚Ä¢ Negative Œî means the system ranked lower-relevance docs higher\n",
      "  ‚Ä¢ Positive Œî means the system ranked higher-relevance docs higher\n",
      "  ‚Ä¢ Use graded relevance when document quality varies significantly\n"
     ]
    }
   ],
   "source": [
    "# Load graded relevance judgments from data/qrels.jsonl\n",
    "graded_qrels = {}\n",
    "qrels_path = Path(\"../data/qrels.jsonl\")\n",
    "with open(qrels_path, 'r') as f:\n",
    "    for line in f:\n",
    "        entry = json.loads(line.strip())\n",
    "        qid = entry['qid']\n",
    "        doc_id = entry['doc_id']\n",
    "        rel = entry['rel']\n",
    "        if qid not in graded_qrels:\n",
    "            graded_qrels[qid] = {}\n",
    "        graded_qrels[qid][doc_id] = rel\n",
    "\n",
    "print(\"üìä Loaded graded relevance judgments from data/qrels.jsonl\")\n",
    "print(f\"Queries with graded qrels: {len(graded_qrels)}\")\n",
    "print(f\"\\nExample: Query 'q2' (global warming):\")\n",
    "print(f\"  climate2: rel={graded_qrels['q2']['climate2']} (highly relevant)\")\n",
    "print(f\"  climate1: rel={graded_qrels['q2']['climate1']} (moderately relevant)\")\n",
    "\n",
    "# Compare binary vs graded NDCG for all queries\n",
    "comparison_results = []\n",
    "\n",
    "for q in queries:\n",
    "    qid = q['id']\n",
    "    \n",
    "    if qid not in graded_qrels:\n",
    "        continue\n",
    "    \n",
    "    # Get rankings\n",
    "    bm25_ranked = bm25_run[qid]\n",
    "    jina_ranked = jina_run[qid] if jina_retriever else []\n",
    "    \n",
    "    # Calculate NDCG with graded relevance\n",
    "    bm25_ndcg_graded = ndcg_at_k(bm25_ranked, graded_qrels[qid], k=3, method=\"exponential\")\n",
    "    jina_ndcg_graded = ndcg_at_k(jina_ranked, graded_qrels[qid], k=3, method=\"exponential\") if jina_retriever else 0.0\n",
    "    \n",
    "    # Calculate NDCG with binary relevance (convert all rel>0 to 1)\n",
    "    binary_qrels = {doc: 1 for doc, rel in graded_qrels[qid].items() if rel > 0}\n",
    "    bm25_ndcg_binary = ndcg_at_k(bm25_ranked, binary_qrels, k=3, method=\"exponential\")\n",
    "    jina_ndcg_binary = ndcg_at_k(jina_ranked, binary_qrels, k=3, method=\"exponential\") if jina_retriever else 0.0\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'Query ID': qid,\n",
    "        'Query': q['query'][:40] + '...',\n",
    "        'BM25 NDCG (Binary)': round(bm25_ndcg_binary, 3),\n",
    "        'BM25 NDCG (Graded)': round(bm25_ndcg_graded, 3),\n",
    "        'BM25 Œî': round(bm25_ndcg_graded - bm25_ndcg_binary, 3),\n",
    "        'Jina NDCG (Binary)': round(jina_ndcg_binary, 3),\n",
    "        'Jina NDCG (Graded)': round(jina_ndcg_graded, 3),\n",
    "        'Jina Œî': round(jina_ndcg_graded - jina_ndcg_binary, 3),\n",
    "    })\n",
    "\n",
    "df_graded_comparison = pd.DataFrame(comparison_results)\n",
    "\n",
    "# Calculate average scores\n",
    "avg_bm25_binary = df_graded_comparison['BM25 NDCG (Binary)'].mean()\n",
    "avg_bm25_graded = df_graded_comparison['BM25 NDCG (Graded)'].mean()\n",
    "avg_jina_binary = df_graded_comparison['Jina NDCG (Binary)'].mean()\n",
    "avg_jina_graded = df_graded_comparison['Jina NDCG (Graded)'].mean()\n",
    "\n",
    "# Create average row\n",
    "average_row = {\n",
    "    'Query ID': 'AVERAGE',\n",
    "    'Query': 'All queries',\n",
    "    'BM25 NDCG (Binary)': round(avg_bm25_binary, 3),\n",
    "    'BM25 NDCG (Graded)': round(avg_bm25_graded, 3),\n",
    "    'BM25 Œî': round(avg_bm25_graded - avg_bm25_binary, 3),\n",
    "    'Jina NDCG (Binary)': round(avg_jina_binary, 3),\n",
    "    'Jina NDCG (Graded)': round(avg_jina_graded, 3),\n",
    "    'Jina Œî': round(avg_jina_graded - avg_jina_binary, 3),\n",
    "}\n",
    "\n",
    "# Add average row to dataframe\n",
    "df_graded_comparison_with_avg = pd.concat([df_graded_comparison, pd.DataFrame([average_row])], ignore_index=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BINARY vs GRADED RELEVANCE COMPARISON (NDCG@3)\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "display(df_graded_comparison_with_avg)\n",
    "\n",
    "print(f\"\\nüí° Key Insights:\")\n",
    "print(f\"  ‚Ä¢ Graded relevance reveals finer differences in ranking quality\")\n",
    "print(f\"  ‚Ä¢ Negative Œî means the system ranked lower-relevance docs higher\")\n",
    "print(f\"  ‚Ä¢ Positive Œî means the system ranked higher-relevance docs higher\")\n",
    "print(f\"  ‚Ä¢ Use graded relevance when document quality varies significantly\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Graded vs Binary Relevance\n",
    "\n",
    "**Use Binary Relevance (0/1) when:**\n",
    "- ‚úÖ Documents are clearly relevant or not (e.g., product search - item matches or doesn't)\n",
    "- ‚úÖ You want simpler annotation (faster, cheaper)\n",
    "- ‚úÖ Using metrics like Precision@k, Recall@k, or MRR\n",
    "- ‚úÖ You have limited annotation resources\n",
    "\n",
    "**Use Graded Relevance (1-3 or 1-5 scale) when:**\n",
    "- ‚úÖ Document quality varies significantly (e.g., research papers, news articles)\n",
    "- ‚úÖ You want to distinguish \"perfect\" from \"acceptable\" results\n",
    "- ‚úÖ Using NDCG or similar metrics that leverage graded judgments\n",
    "- ‚úÖ You need fine-grained evaluation of ranking quality\n",
    "- ‚úÖ User satisfaction depends on result quality, not just relevance\n",
    "\n",
    "**Real-World Examples:**\n",
    "- **Search engines**: Use graded relevance (Google uses 5-point scale)\n",
    "- **E-commerce**: Often binary (product matches query or not)\n",
    "- **Research retrieval**: Graded (papers can be highly/moderately/tangentially relevant)\n",
    "- **FAQ matching**: Binary (answer is correct or not)\n",
    "\n",
    "**üí° Best Practice:** Start with binary relevance for quick evaluation, then add graded relevance for production systems where ranking quality matters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "### BM25 Strengths:\n",
    "‚úÖ Excellent with **exact keyword matches**  \n",
    "‚úÖ Strong on **rare technical terms** (high IDF)  \n",
    "‚úÖ Fast and efficient  \n",
    "‚úÖ Interpretable (you can see which terms matched)  \n",
    "\n",
    "### BM25 Weaknesses:\n",
    "‚ùå No semantic understanding (\"global warming\" ‚â† \"greenhouse gas\")  \n",
    "‚ùå Struggles with **paraphrasing**  \n",
    "‚ùå Can't handle **conceptual queries**  \n",
    "‚ùå Vocabulary mismatch problems  \n",
    "\n",
    "### Jina Embeddings Strengths:\n",
    "‚úÖ Understands **semantic similarity**  \n",
    "‚úÖ Handles **paraphrasing** well  \n",
    "‚úÖ Works with **conceptual queries**  \n",
    "‚úÖ Robust to vocabulary mismatch  \n",
    "‚úÖ Multilingual and multimodal (text + images)  \n",
    "\n",
    "### Jina Embeddings Weaknesses:\n",
    "‚ùå Computationally expensive  \n",
    "‚ùå Requires GPU for fast inference at scale  \n",
    "‚ùå Less interpretable (black box)  \n",
    "‚ùå May miss exact matches if not in training data  \n",
    "\n",
    "### Best Practice:\n",
    "üéØ **Hybrid retrieval** - Combine both approaches!\n",
    "- Use BM25 for keyword matches\n",
    "- Use embeddings for semantic understanding\n",
    "- Merge and re-rank results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Inspection (Jina Embeddings)\n",
    "\n",
    "Let's visualize how Jina understands semantic relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Pairwise Semantic Similarities\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>similarity</th>\n",
       "      <th>interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climate change</td>\n",
       "      <td>global warming</td>\n",
       "      <td>0.915079</td>\n",
       "      <td>Very similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>0.837106</td>\n",
       "      <td>Very similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neural networks</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>0.827342</td>\n",
       "      <td>Very similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quantum computing</td>\n",
       "      <td>classical computing</td>\n",
       "      <td>0.869445</td>\n",
       "      <td>Very similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>climate change</td>\n",
       "      <td>quantum computing</td>\n",
       "      <td>0.731588</td>\n",
       "      <td>Similar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text1                    text2  similarity interpretation\n",
       "0     climate change           global warming    0.915079   Very similar\n",
       "1   machine learning  artificial intelligence    0.837106   Very similar\n",
       "2    neural networks            deep learning    0.827342   Very similar\n",
       "3  quantum computing      classical computing    0.869445   Very similar\n",
       "4     climate change        quantum computing    0.731588        Similar"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if jina_embedder:\n",
    "    print(\"üî¨ Pairwise Semantic Similarities\\n\")\n",
    "    \n",
    "    pairs = [\n",
    "        (\"climate change\", \"global warming\"),\n",
    "        (\"machine learning\", \"artificial intelligence\"),\n",
    "        (\"neural networks\", \"deep learning\"),\n",
    "        (\"quantum computing\", \"classical computing\"),\n",
    "        (\"climate change\", \"quantum computing\"),  # Unrelated\n",
    "    ]\n",
    "    \n",
    "    similarity_data = []\n",
    "    \n",
    "    for text1, text2 in pairs:\n",
    "        emb1 = jina_embedder.encode([text1], prompt_name=\"passage\")[0]\n",
    "        emb2 = jina_embedder.encode([text2], prompt_name=\"passage\")[0]\n",
    "        \n",
    "        # Cosine similarity (dot product for normalized vectors)\n",
    "        similarity = float(np.dot(emb1, emb2))\n",
    "        \n",
    "        similarity_data.append({\n",
    "            'text1': text1,\n",
    "            'text2': text2,\n",
    "            'similarity': similarity,\n",
    "            'interpretation': (\n",
    "                'Very similar' if similarity > 0.8 else\n",
    "                'Similar' if similarity > 0.6 else\n",
    "                'Somewhat similar' if similarity > 0.4 else\n",
    "                'Different'\n",
    "            )\n",
    "        })\n",
    "    \n",
    "    df_similarity = pd.DataFrame(similarity_data)\n",
    "    display(df_similarity)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Jina embeddings not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Both BM25 and neural embeddings have their place in modern IR systems:\n",
    "\n",
    "- **BM25**: Fast, interpretable, great for exact matches\n",
    "- **Embeddings**: Semantic understanding, handles paraphrasing\n",
    "- **Best approach**: Hybrid systems that combine both strengths\n",
    "\n",
    "For production systems, consider:\n",
    "1. First-stage retrieval with BM25 (fast, broad recall)\n",
    "2. Re-ranking with embeddings (precise, semantic)\n",
    "3. Evaluation metrics (Precision@k, MRR, NDCG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
